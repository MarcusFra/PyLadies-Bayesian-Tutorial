{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting simple: Linear Regression\n",
    "As so often, we will start relatively simple with a Linear Regression. Sounds maybe a bit boring but don't worry, I will show you later how to extend this model to something slightly more complex.\n",
    "\n",
    "## Short Look at the Data\n",
    "For this tutorial, I will use rental data that I scraped from Immoscout24. For a more detailed description and information on how I scraped the data set, you can check its description on [kaggle](https://www.kaggle.com/corrieaar/apartment-rental-offers-in-germany) where I occasionally also update the data.\n",
    "For this analysis, we will concentrate on rental offers in Berlin but of course feel free to try out later different cities or areas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from utils import iqr, iqr_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"../data/immo_data.csv\", dtype={\"geo_plz\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the data, we will do a bit of preprocessing: We remove outliers where either the living area or the total rent is too low or too high. To remove outliers, the [Inter quartile range (IQR)](https://en.wikipedia.org/wiki/Interquartile_range#Outliers) is used. The IQR rule marks everything as outlier that's too far from the middle range of the data. Most of the data we throw away this way were typos or similar with unreasonable input values.\n",
    "For a more thorough analysis, it might be useful to check that we don't throw away real cases and instead incorporate the outliers in further analysis.\n",
    "\n",
    "As target variable we will use the variable `totalRent`, which in most cases is the sum of the base rent and a service fee (heating etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"totalRent\"] = np.where(d[\"totalRent\"].isnull(), d[\"baseRent\"], d[\"totalRent\"])\n",
    "\n",
    "# since log doesn't work with 0, we replace 0 with 0.5\n",
    "# seems reasonable to say hat a rent of 0€ is the same as 50ct\n",
    "d[\"livingSpace_m\"] =  np.where(d[\"livingSpace\"] <= 0, 0.5, d[\"livingSpace\"])\n",
    "d[\"totalRent_m\"] = np.where(d[\"totalRent\"] <= 0, 0.5, d[\"totalRent\"])\n",
    "d[\"logRent\"] = np.log(d[\"totalRent_m\"])\n",
    "d[\"logSpace\"] = np.log(d[\"livingSpace_m\"])\n",
    "\n",
    "not_outlier = iqr_rule(d[\"logSpace\"], factor=1.5) & iqr_rule(d[\"logRent\"], factor=1.5)\n",
    "d = d[not_outlier]\n",
    "berlin = d[(d.regio1 == \"Berlin\")].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, we want to predict the rent (`totalRent`) by the living area (`livingSpace`).\n",
    "\n",
    "You can have a short look at the data and these two variables!\n",
    "\n",
    "For example:\n",
    "- What is the average rent in Berlin?\n",
    "- What is the average size of a flat in Berlin?\n",
    "- Plot rent vs living space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with the data, we will rescale and normalize the living area and also rescale the total rent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin[\"livingSpace_s\"] = (berlin[\"livingSpace\"] - berlin[\"livingSpace\"].mean()) / np.std(berlin[\"livingSpace\"])\n",
    "berlin[\"totalRent_s\"] = berlin[\"totalRent\"] / 100\n",
    "\n",
    "# saving for later\n",
    "berlin.to_csv(\"../data/berlin.csv\", encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC) # special quoting necessary because otherwise description messes up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to standardize/destandardize area a few times, so we will use small helper functions for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are also saved in src/utils.py\n",
    "def standardize_area(x):\n",
    "    return ( x - berlin[\"livingSpace\"].mean()) / np.std(berlin[\"livingSpace\"])\n",
    "    \n",
    "def destandardize_area(x):\n",
    "    return ( x * np.std(berlin[\"livingSpace\"]) ) + berlin[\"livingSpace\"].mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.scatter(berlin.livingSpace_s, berlin.totalRent_s, s=4)\n",
    "plt.title(\"Rent by (standardized) living area\")\n",
    "plt.xlabel(\"Living Area [sqm]\")\n",
    "plt.ylabel(\"Monthly Rent [100€]\")\n",
    "plt.axvline(x=0, c=\"k\", linewidth=1)\n",
    "plt.axhline(y=np.mean(berlin.totalRent_s), c=\"k\", linewidth=1, linestyle=\"--\", label=\"Average Rent\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot, it roughly looks like a linear relationship between living area and monthly rent. Indeed, the bigger the flat the more expensive it should be. So we will start our modelling with a linear model.\n",
    "\n",
    "So in math notation, our model can be written as follows:\n",
    "\n",
    "$$ \\text{rent} \\approx \\alpha + \\beta \\text{area} $$\n",
    "\n",
    "This is the same as\n",
    "$$ \\text{rent} = \\alpha + \\beta \\text{area} + \\epsilon$$\n",
    "where $\\epsilon$ is normally distributed, i.e. $\\epsilon \\sim \\text{Normal}(0, \\sigma)$. This can be rewritten as\n",
    "$$ \\text{rent} \\sim \\text{Normal}(\\alpha + \\beta \\text{area}, \\sigma).$$\n",
    "\n",
    "For easier reading, we rewrite this again:\n",
    "$$\\begin{align*} \\text{rent} &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n",
    "\\mu &= \\alpha + \\beta \\text{area}\n",
    "\\end{align*}$$\n",
    "This will be our first model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Bayesian ingredient: Priors\n",
    "\n",
    "Before implementing this model, let's shortly think about what the parameters $\\alpha$ and $\\beta$ mean here.\n",
    "\n",
    "We will use the model with our rescaled data and thus $\\alpha$ the __intercept is the rental price of an average sized flat__. (For averaged sized flats, the scaled area is 0).\n",
    "\n",
    "$\\beta$ is then the __increase in rent__ if the flat is one standard deviation larger. One standard deviation is 29sqm which is roughly the average size for a room (check living space divided by number of rooms `noRooms`). Thus $\\beta$ is roughly the increase in rent if the flat would have one more room. \n",
    "\n",
    "$\\sigma$ is __how much the rent can differ__ for two flats of the same size. Concretely, it is how much the rent can differ from the average rent for flats of the same size. As our model says that the rent is normally distributed, about 95% of the cases should be within $2\\sigma$ of the average rent.\n",
    "As error term, $\\sigma$ is always positive.\n",
    "\n",
    "Thinking about what the parameters mean beforehand is very important in a Bayesian analysis since we need to specify priors. Priors are what we think the parameters could be before seeing the data. And, obviously, to be able to say what range the parameters would be in, it would be good to know what the parameters mean.\n",
    "\n",
    "\n",
    "If we don't know anything about the problems, we might want to specify priors that are very uninformative and vague. \n",
    "We could for example specify $\\alpha$ and $\\beta$ as being somewhere between -10,000 and + 10,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as mod:\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10000)\n",
    "    beta = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyMC-Model is specified in a context. Before we can actually specify the model, we need to specify the priors, since, as usual in Python, each variable we want to use need to declared beforehand.\n",
    "In PyMC, you always need to specify the name of the variable twice. This is so that the variable knows its own name.\n",
    "\n",
    "If you print the model, it renders nicely in a more mathy looking description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add to the model by opening the context again.\n",
    "To for example add a prior for sigma, we can proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mod:\n",
    "    sigma = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\sigma$ as error term is always a positive variable, we need to use a distribution that is also always positive. One commonly used distribution for this is the Half-Normal. A normal distribution that is cut in half and only positive.\n",
    "Other commonly used distributions for $\\sigma$ are for example the Exponential or the Half-Cauchy.\n",
    "\n",
    "Now that we specified some priors, we can write out the complete model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mod:\n",
    "    mu = ...\n",
    "    \n",
    "    rent = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyMC-Model is written very similar to how the model was specified above. \n",
    "\n",
    "Note that for the outcome variable, we need to specify the observed data.\n",
    "Usually the whole model is written as one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as mod:\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10000)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=10000)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=10000)\n",
    "    \n",
    "    mu = alpha + beta*berlin[\"livingSpace_s\"] \n",
    "    rent = pm.Normal(\"rent\", mu=mu, sigma=sigma,\n",
    "                    observed=berlin[\"totalRent_s\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially in the beginning, when starting out with Bayesian modelling, picking priors can seem a bit daring. \n",
    "Does it make a difference if we use $\\text{Normal}(0,100)$ or $\\text{Normal}(0, 1000)$?\n",
    "What's with using different distributions?\n",
    "\n",
    "\n",
    "There are a few tips that help a bit with picking a good prior. The first one is to visualize your priors. We can do this with PyMC by sampling from our priors.\n",
    "This is the similar to sampling from the specified distributions using numpy or scipy. However, on top of sampling from the probability distributions, it then also computes $\\mu$ (the linear part of the model) using the samples and the predictor variables. It then uses the computed $\\mu$ and the samples from $\\sigma$ to sample possible outcome values. Even though we specified the target variable (in Machine Learning this one is usually called `y`) it does not use this (yet) and is thus very quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mod:\n",
    "    priors = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [ArviZ](https://arviz-devs.github.io/arviz/) to keep track of the different outputs computed from our model and to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "pm_data = az.from_pymc3(prior = priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArviZ comes with many plots that are useful to analyze Bayesian models.\n",
    "Let's look at the priors for our three model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look super interesting, it is basically just a density plot of the distributions we gave for the priors.\n",
    "More interesting is to visualize what rental prices these prior distributions would produce given the predictor data.\n",
    "Unfortunately, there is no ArviZ plot for this yet, but we can do this ourselves without too much work.\n",
    "\n",
    "The object `priors` contains a numpy array for `rent`. Check what it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each observation in our dataframe (7092 obs) it computed 1000 samples for possible rent prices, using the samples from `alpha`, `beta`, and `sigma` together with the corresponding living area from this observation.\n",
    "\n",
    "We can flatten the matrix to obtain one big array and plot a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_rents = priors[\"rent\"].flatten()*100\n",
    "# plot histogram\n",
    "plt.hist(prior_rents, alpha=0.9, ec=\"darkblue\", bins=70)\n",
    "plt.title(\"Histogram over possible range of rental prices\")\n",
    "plt.xlabel(\"Monthly Rent [€]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with the histogram over the actual rental prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(berlin[\"totalRent_s\"]*100, alpha=0.9, ec=\"darkblue\", bins=70)\n",
    "plt.title(\"Histogram over the actual rental prices\")\n",
    "plt.xlabel(\"Monthly Rent [€]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms don't look very similar and the range of the sampled rents is completly off! A rent of up 50,000€ per month doesn't sound very realistic.\n",
    "\n",
    "\n",
    "Another good way to understand the prior better is to visualize the model that it would produce. In our case, the model is a line determined by the intercept $\\alpha$ and the slope $\\beta$. \n",
    "We can thus sample 50 $\\alpha$ and $\\beta$s and multiply this with the range of area values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_s = np.linspace(start=-2, stop=3.5, num=50)\n",
    "draws = np.random.choice(len(priors[\"alpha\"]), replace=False, size=50)\n",
    "\n",
    "alpha = ...\n",
    "beta = ...\n",
    "\n",
    "mu = ...\n",
    "\n",
    "\n",
    "plt.plot(destandardize_area(area_s), mu*100, c=\"#737373\", alpha=0.5)\n",
    "plt.xlabel(\"Living Area [sqm]\")\n",
    "plt.ylabel(\"Price [€]\")\n",
    "plt.title(\"Linear model according to our prior\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: \n",
    "Use `plt.axhline(y=my_rent)` to compare the sampled lines with your own rent, the most expensive, reasonable rent you can think off and the cheapest possible rent you can think off. I also like to google what is the known most expensive rent one can find in Berlin (or elsewhere) and see how it compares to the model.\n",
    "\n",
    "You could also add these benchmarks to the histogram using `plt.axvline(x=my_rent)`.\n",
    "\n",
    "These priors are obviously not very realistic! Luckily, we all know a bit about rents, so even without looking at the data, we can think of better priors.\n",
    "\n",
    "Write a new model `mod_informed` that uses the same linear part as above, but better priors. You can use the same distributions as above and only change its parameters. I recommend you to try various priors and check what effects they have on the resulting model and its outputs.\n",
    "\n",
    "Remember: \n",
    "- $\\alpha$ the intercept is the rental price of an average sized flat (averaged sized flat is 77sqm).\n",
    "- $\\beta$ the slope is roughly the increase in rent if the flat would have one more room\n",
    "- $\\sigma$ is how much the rent can differ for two flats of the same size. As error term, $\\sigma$ is always positive.\n",
    "\n",
    "Always keep in mind the scale of your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as mod_informed:\n",
    "    # new model goes here\n",
    "    \n",
    "    mu = ...\n",
    "    \n",
    "    rent = ...\n",
    "    \n",
    "    priors = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made functions for the above plot, so you don't have to copy the whole plot code: `compare_hist(priors, berlin)` to plot the two histograms and `draw_models(priors, berlin)` to plot sampled lines from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compare_hist, draw_models\n",
    "\n",
    "compare_hist(priors, berlin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_models(priors, berlin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to explore regarding different priors:\n",
    "- We've seen above what happens when we use overly vague priors, what happens if we use very narrow priors? What problems could arise?\n",
    "- So far, we've only used the normal distribution for the priors. Try out some different distributions, e.g.\n",
    "    - Uniform distribution, e.g. over -1000 to + 1000\n",
    "    - Student-T distribution\n",
    "- Since we know that rents should increase for larger flats, we know that the slope $\\beta$ should be positive, how could we bias our priors to positive values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand better how something works, it often helps to implement it oneself. Try implementing yourself sampling from the prior using only numpy or scipy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyLadies-Bayesian-Tutorial",
   "language": "python",
   "name": "pyladies-bayesian-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
